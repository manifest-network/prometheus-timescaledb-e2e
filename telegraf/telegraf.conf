[agent]
  interval = "10s"
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  flush_interval = "10s"

[[inputs.http_listener_v2]]
  service_address = ":9273"
  paths = ["/write"]
  data_format = "prometheusremotewrite"

[[inputs.internal]]

[[processors.filter]]
  namepass = ["prometheus_remote_write"]

[[processors.starlark]]
  source = '''
def apply(metric):
    for k, v in metric.fields.items():
        # Set the Telegraf measurement to the Prometheus metric name
        metric.name = k.lower()
        if len(metric.name) > 63:
            metric.name = metric.name[:63]
        # Move the metric value under a single value field
        metric.fields["value"] = v
        metric.fields.pop(k)
    return metric
'''

[[outputs.postgresql]]
  namepass = ["blockchain_height",
      "manifest_tokenomics_denom_metadata",
      "manifest_tokenomics_token_count",
      "manifest_tokenomics_total_supply",
      "total_unique_user",
      "total_unique_group",
      "total_mfx_burned",
       "total_mfx_minted",
       "total_tx_count"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "testnet"

  create_templates = [
    # Create the testnet hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "testnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" double precision, PRIMARY KEY (time, tags));
    SELECT create_hypertable('{{ .table.WithSchema "testnet" }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('{{ .table.WithSchema "testnet" }}', INTERVAL '1 year');
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_testnet_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "tags"      JSONB,
        "value"     TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = testnet, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS "timestamp",
          (
             SELECT COALESCE(jsonb_object_agg(k, v), '{}'::JSONB)
                 FROM jsonb_each(d.tags) AS t(k, v)
             WHERE k IN ('supply')
          )                                 AS "tags",
          max(d.value)::TEXT                AS "value"
      FROM testnet.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1, 2
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_testnet_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_testnet_{{ .table.Name }} AS
    SELECT
      d.time         AS "timestamp",
      (
        SELECT COALESCE(jsonb_object_agg(k, v), '{}'::JSONB)
        FROM jsonb_each(d.tags) AS t(k, v)
        WHERE k IN ('supply')
      )           AS "tags",
      d.value::TEXT  AS "value"
    FROM {{ .table.WithSchema "testnet" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_testnet_{{ .table.Name }} TO web_anon;
    '''
  ]
  tagpass = {"manifest_tier" = ["testnet"]}

[[outputs.postgresql]]
  namepass = ["blockchain_height",
      "manifest_tokenomics_denom_metadata",
      "manifest_tokenomics_token_count",
      "manifest_tokenomics_total_supply",
      "total_unique_user",
      "total_unique_group",
      "total_mfx_burned",
      "total_mfx_minted",
      "total_tx_count"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "mainnet"

  create_templates = [
    # Create the mainnet hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "mainnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" double precision, PRIMARY KEY (time, tags));
    SELECT create_hypertable('{{ .table.WithSchema "mainnet" }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('{{ .table.WithSchema "mainnet" }}', INTERVAL '1 year');
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_mainnet_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "tags"      JSONB,
        "value"     TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = mainnet, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS timestamp,
          (
             SELECT COALESCE(jsonb_object_agg(k, v), '{}'::JSONB)
                 FROM jsonb_each(d.tags) AS t(k, v)
             WHERE k IN ('supply')
          ) AS "tags",
          max(d.value)::TEXT                AS "value"
      FROM mainnet.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1, 2
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_mainnet_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_mainnet_{{ .table.Name }} AS
    SELECT
      d.time        AS "timestamp",
      (
        SELECT COALESCE(jsonb_object_agg(k, v), '{}'::JSONB)
        FROM jsonb_each(d.tags) AS t(k, v)
        WHERE k IN ('supply')
      )           AS tags,
      d.value::TEXT AS "value"
    FROM {{ .table.WithSchema "mainnet" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_mainnet_{{ .table.Name }} TO web_anon;
    '''
  ]
  tagpass = {"manifest_tier" = ["mainnet"]}

# TODO: Create continuous aggregates
[[outputs.postgresql]]
  namepass = ["web_requests", "system_tcp_sent", "system_tcp_received", "system_network_sent", "system_network_received", "decentralized_web_requests"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "cumsum"
  create_templates = [
    # Create the common hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "cumsum" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" double precision, PRIMARY KEY (time, tags));
    SELECT create_hypertable('cumsum.{{ .table.Name }}', 'time', if_not_exists => TRUE);
    ''',
    # Create a cumulative sum function for the given table (metric)
    '''
    CREATE OR REPLACE FUNCTION api.get_cumsum_{{ .table.Name }} (
      p_interval INTERVAL,
      p_from     TIMESTAMPTZ,
      p_to       TIMESTAMPTZ
    )
    RETURNS TABLE (
      "timestamp" TIMESTAMPTZ,
      "value"     DOUBLE PRECISION
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = cumsum, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      WITH raw AS (
        SELECT
          d.time as "time",
          SUM(sum(d.value)) OVER (ORDER BY time) AS cumulative
        FROM {{ .table.WithSchema "cumsum" }} as d
        GROUP BY d.time
      ),
      filtered AS (
        SELECT *
        FROM raw
        WHERE time >= p_from AND time <= p_to
      ),
      bucketed AS (
        SELECT
          time_bucket(p_interval, time) AS ts,
          MAX(cumulative)               AS mc
        FROM filtered
        GROUP BY ts
      )
      SELECT
        ts as "timestamp",
        mc as "value"
      FROM bucketed
      ORDER BY ts;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_cumsum_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest cumsum value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_cumsum_{{ .table.Name }} AS
      SELECT
          d.time AS "timestamp",
          sum(sum(d.value)) OVER(ORDER BY d.time) AS "value"
      FROM {{ .table.WithSchema "cumsum" }} as d
      GROUP BY d.time
      ORDER BY d.time DESC
      LIMIT 1;
    GRANT SELECT ON api.latest_cumsum_{{ .table.Name }} TO web_anon;
    '''
  ]

[[outputs.postgresql]]
  namedrop = ["blockchain_height",
      "manifest_tokenomics_denom_metadata",
      "manifest_tokenomics_token_count",
      "manifest_tokenomics_total_supply",
      "total_unique_user",
      "total_unique_group",
      "total_mfx_burned",
      "total_mfx_minted",
      "total_tx_count",
      "web_requests",
      "system_tcp_sent",
      "system_tcp_received",
      "system_network_sent",
      "system_network_received",
      "decentralized_web_requests"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "common"

  create_templates = [
    # Create the common hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "common" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" double precision, PRIMARY KEY (time, tags));
    SELECT create_hypertable('common.{{ .table.Name }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('common.{{ .table.Name }}', INTERVAL '1 year');
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "value" TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = common, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS timestamp,
          max(d.value)::TEXT                 AS "value"
      FROM common.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_{{ .table.Name }} AS
    SELECT
      d.time         AS "timestamp",
      d.value::TEXT  AS "value"
    FROM {{ .table.WithSchema "common" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_{{ .table.Name }} TO web_anon;
    '''
  ]

[[outputs.prometheus_client]]
  listen = ":9274"
  path = "/metrics"
  expiration_interval = "60s"
  collectors_exclude = ["gocollector", "process"]
