[agent]
  interval = "10s"
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  flush_interval = "10s"

[[inputs.http_listener_v2]]
  service_address = ":9273"
  paths = ["/write"]
  data_format = "prometheusremotewrite"

[[inputs.internal]]

[[processors.filter]]
  namepass = ["prometheus_remote_write"]

[[processors.starlark]]
  source = '''
def apply(metric):
    for k, v in metric.fields.items():
        # Set the Telegraf measurement to the Prometheus metric name
        metric.name = k.lower()
        if len(metric.name) > 63:
            metric.name = metric.name[:63]
        # Move the metric value under a single value field
        metric.fields["value"] = v
        metric.fields.pop(k)
    return metric
'''

# Retrieve real metric value from tag
[[processors.starlark]]
  namepass = ["manifest_tokenomics_total_supply", "manifest_tokenomics_excluded_supply", "locked_tokens"]
  source = '''
def apply(metric):
    if "supply" in metric.tags:
        metric.fields["value"] = metric.tags["supply"]
    elif "excluded_supply" in metric.tags:
        metric.fields["value"] = metric.tags["excluded_supply"]
    elif "amount" in metric.tags:
        metric.fields["value"] = metric.tags["amount"]

    return metric
'''

# Write the metric as TEXT and use a trigger to convert it to NUMERIC in order to get the accurate value
#
# Workaround for https://github.com/jackc/pgx/issues/1362
# Telegraf is still using pgx v4
[[outputs.postgresql]]
  namepass = ["manifest_tokenomics_total_supply", "manifest_tokenomics_excluded_supply", "locked_tokens"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "tmp_testnet"

  create_templates = [
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "tmp_testnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" TEXT, PRIMARY KEY (time, tags));
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "testnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" NUMERIC, PRIMARY KEY (time, tags));
    SELECT create_hypertable('{{ .table.WithSchema "tmp_testnet" }}', 'time', if_not_exists => TRUE);
    SELECT create_hypertable('{{ .table.WithSchema "testnet" }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('{{ .table.WithSchema "tmp_testnet" }}', INTERVAL '1 day');
    SELECT add_retention_policy('{{ .table.WithSchema "testnet" }}', INTERVAL '1 year');
    ''',
    '''
    CREATE OR REPLACE FUNCTION api.tmp_to_testnet_{{ .table.Name }}()
    RETURNS trigger AS $$$$
    BEGIN
      INSERT INTO {{ .table.WithSchema "testnet" }}(time, tags, value)
        VALUES (NEW.time, NEW.tags, NEW.value::NUMERIC)
      ON CONFLICT (time, tags)
        DO UPDATE SET value = EXCLUDED.value;
      RETURN NEW;
    END;
    $$$$ LANGUAGE plpgsql;

    CREATE TRIGGER trg_tmp_to_testnet_{{ .table.Name }}
      AFTER INSERT ON {{ .table.WithSchema "tmp_testnet" }}
      FOR EACH ROW
      EXECUTE FUNCTION api.tmp_to_testnet_{{ .table.Name }}();
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_testnet_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "value"     TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = testnet, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS "timestamp",
          max(d.value)::TEXT                AS "value"
      FROM testnet.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_testnet_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_testnet_{{ .table.Name }} AS
    SELECT
      d.time         AS "timestamp",
      d.value::TEXT  AS "value"
    FROM {{ .table.WithSchema "testnet" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_testnet_{{ .table.Name }} TO web_anon;
    '''
  ]
  tagpass = {"manifest_tier" = ["testnet"]}

# Write the metric as TEXT and use a trigger to convert it to NUMERIC in order to get the accurate value
#
# Workaround for https://github.com/jackc/pgx/issues/1362
# Telegraf is still using pgx v4
[[outputs.postgresql]]
  namepass = ["manifest_tokenomics_total_supply", "manifest_tokenomics_excluded_supply"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "tmp_mainnet"

  create_templates = [
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "tmp_mainnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" TEXT, PRIMARY KEY (time, tags));
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "mainnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" NUMERIC, PRIMARY KEY (time, tags));
    SELECT create_hypertable('{{ .table.WithSchema "tmp_mainnet" }}', 'time', if_not_exists => TRUE);
    SELECT create_hypertable('{{ .table.WithSchema "mainnet" }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('{{ .table.WithSchema "tmp_mainnet" }}', INTERVAL '1 day');
    SELECT add_retention_policy('{{ .table.WithSchema "mainnet" }}', INTERVAL '1 year');
    ''',
    '''
    CREATE OR REPLACE FUNCTION api.tmp_to_mainnet_{{ .table.Name }}()
    RETURNS trigger AS $$$$
    BEGIN
      INSERT INTO {{ .table.WithSchema "mainnet" }}(time, tags, value)
        VALUES (NEW.time, NEW.tags, NEW.value::NUMERIC)
      ON CONFLICT (time, tags)
        DO UPDATE SET value = EXCLUDED.value;
      RETURN NEW;
    END;
    $$$$ LANGUAGE plpgsql;

    CREATE TRIGGER trg_tmp_to_mainnet_{{ .table.Name }}
      AFTER INSERT ON {{ .table.WithSchema "tmp_mainnet" }}
      FOR EACH ROW
      EXECUTE FUNCTION api.tmp_to_mainnet_{{ .table.Name }}();
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_mainnet_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "value"     TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = mainnet, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS "timestamp",
          max(d.value)::TEXT                AS "value"
      FROM mainnet.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_mainnet_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_mainnet_{{ .table.Name }} AS
    SELECT
      d.time         AS "timestamp",
      d.value::TEXT  AS "value"
    FROM {{ .table.WithSchema "mainnet" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_mainnet_{{ .table.Name }} TO web_anon;
    '''
  ]
  tagpass = {"manifest_tier" = ["mainnet"]}

[[outputs.postgresql]]
  namepass = ["blockchain_height",
      "manifest_tokenomics_denom_metadata",
      "manifest_tokenomics_token_count",
      "total_unique_user",
      "total_unique_group",
      "total_mfx_burned",
      "total_mfx_minted",
      "total_tx_count",
  ]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "testnet"

  create_templates = [
    # Create the testnet hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "testnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" NUMERIC, PRIMARY KEY (time, tags));
    SELECT create_hypertable('{{ .table.WithSchema "testnet" }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('{{ .table.WithSchema "testnet" }}', INTERVAL '1 year');
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_testnet_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "value"     TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = testnet, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS "timestamp",
          max(d.value)::TEXT                AS "value"
      FROM testnet.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_testnet_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_testnet_{{ .table.Name }} AS
    SELECT
      d.time         AS "timestamp",
      d.value::TEXT  AS "value"
    FROM {{ .table.WithSchema "testnet" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_testnet_{{ .table.Name }} TO web_anon;
    '''
  ]
  tagpass = {"manifest_tier" = ["testnet"]}

[[outputs.postgresql]]
  namepass = ["blockchain_height",
      "manifest_tokenomics_denom_metadata",
      "manifest_tokenomics_token_count",
      "total_unique_user",
      "total_unique_group",
      "total_mfx_burned",
      "total_mfx_minted",
      "total_tx_count",
  ]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "mainnet"

  create_templates = [
    # Create the mainnet hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "mainnet" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" NUMERIC, PRIMARY KEY (time, tags));
    SELECT create_hypertable('{{ .table.WithSchema "mainnet" }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('{{ .table.WithSchema "mainnet" }}', INTERVAL '1 year');
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_mainnet_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "value"     TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = mainnet, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS timestamp,
          max(d.value)::TEXT                AS "value"
      FROM mainnet.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1, 2
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_mainnet_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_mainnet_{{ .table.Name }} AS
    SELECT
      d.time        AS "timestamp",
      d.value::TEXT AS "value"
    FROM {{ .table.WithSchema "mainnet" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_mainnet_{{ .table.Name }} TO web_anon;
    '''
  ]
  tagpass = {"manifest_tier" = ["mainnet"]}

# TODO: Create continuous aggregates
[[outputs.postgresql]]
  namepass = ["web_requests", "system_tcp_sent", "system_tcp_received", "system_network_sent", "system_network_received", "decentralized_web_requests"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "cumsum"
  create_templates = [
    # Create the common hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "cumsum" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" NUMERIC, PRIMARY KEY (time, tags));
    SELECT create_hypertable('cumsum.{{ .table.Name }}', 'time', if_not_exists => TRUE);
    ''',
    # Create a cumulative sum function for the given table (metric)
    '''
    CREATE OR REPLACE FUNCTION api.get_cumsum_{{ .table.Name }} (
      p_interval INTERVAL,
      p_from     TIMESTAMPTZ,
      p_to       TIMESTAMPTZ
    )
    RETURNS TABLE (
      "timestamp" TIMESTAMPTZ,
      "value"     NUMERIC
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = cumsum, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      WITH raw AS (
        SELECT
          d.time as "time",
          SUM(sum(d.value)) OVER (ORDER BY time) AS cumulative
        FROM {{ .table.WithSchema "cumsum" }} as d
        GROUP BY d.time
      ),
      filtered AS (
        SELECT *
        FROM raw
        WHERE time >= p_from AND time <= p_to
      ),
      bucketed AS (
        SELECT
          time_bucket(p_interval, time) AS ts,
          MAX(cumulative)               AS mc
        FROM filtered
        GROUP BY ts
      )
      SELECT
        ts as "timestamp",
        mc as "value"
      FROM bucketed
      ORDER BY ts;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_cumsum_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest cumsum value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_cumsum_{{ .table.Name }} AS
      SELECT
          d.time AS "timestamp",
          sum(sum(d.value)) OVER(ORDER BY d.time) AS "value"
      FROM {{ .table.WithSchema "cumsum" }} as d
      GROUP BY d.time
      ORDER BY d.time DESC
      LIMIT 1;
    GRANT SELECT ON api.latest_cumsum_{{ .table.Name }} TO web_anon;
    '''
  ]

[[outputs.postgresql]]
  namepass = ["manifest_geo_latitude", "manifest_geo_longitude", "manifest_geo_metadata"]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "geo"

[[outputs.postgresql]]
  namedrop = ["blockchain_height",
      "manifest_tokenomics_denom_metadata",
      "manifest_tokenomics_token_count",
      "manifest_tokenomics_total_supply",
      "total_unique_user",
      "total_unique_group",
      "total_mfx_burned",
      "total_mfx_minted",
      "total_tx_count",
      "web_requests",
      "system_tcp_sent",
      "system_tcp_received",
      "system_network_sent",
      "system_network_received",
      "decentralized_web_requests",
      "manifest_geo_metadata",
      "manifest_geo_latitude",
      "manifest_geo_longitude",
      "manifest_tokenomics_excluded_supply",
  ]
  connection = "host=timescaledb user=postgres password=postgres dbname=metrics sslmode=disable"
  column_name_length_limit = 63
  tags_as_jsonb = true
  schema = "common"

  create_templates = [
    # Create the common hypertable and retention policy
    '''
    CREATE TABLE IF NOT EXISTS {{ .table.WithSchema "common" }} ("time" TIMESTAMPTZ, "tags" JSONB, "value" NUMERIC, PRIMARY KEY (time, tags));
    SELECT create_hypertable('common.{{ .table.Name }}', 'time', if_not_exists => TRUE);
    SELECT add_retention_policy('common.{{ .table.Name }}', INTERVAL '1 year');
    ''',
    # Create an aggregation function for the given table (metric)
    # This function relies on the time_bucket function from TimescaleDB to aggregate data
    '''
    CREATE OR REPLACE FUNCTION api.get_agg_{{ .table.Name }} (
        p_interval INTERVAL,
        p_from TIMESTAMPTZ,
        p_to TIMESTAMPTZ
    )
    RETURNS TABLE (
        "timestamp" TIMESTAMPTZ,
        "value" TEXT
    )
    LANGUAGE plpgsql
    STRICT
    SECURITY DEFINER
    SET search_path = common, internal, public
    AS $$$$
    BEGIN
      -- Ensure p_from is less than or equal to p_to
      IF p_from > p_to THEN
        RAISE EXCEPTION 'p_from must be less than or equal to p_to';
      END IF;

      -- Ensure p_interval is a positive interval
      IF  p_interval <= INTERVAL '0' THEN
        RAISE EXCEPTION 'p_interval must be a positive interval';
      END IF;

      -- Ensure p_interval is not larger than the time range
      IF p_interval > (p_to - p_from) THEN
        RAISE EXCEPTION 'p_interval must not be larger than the time range between p_from and p_to';
      END IF;

      RETURN QUERY
      SELECT
          time_bucket(p_interval, d.time)   AS timestamp,
          max(d.value)::TEXT                 AS "value"
      FROM common.{{ .table.Name }} as d
      WHERE d.time >= p_from AND d.time <= p_to
      GROUP BY 1
      ORDER BY 1 DESC;
    END;
    $$$$;
    GRANT EXECUTE ON FUNCTION api.get_agg_{{ .table.Name }}(interval, timestamptz, timestamptz) TO web_anon;
    ''',
    # Create a view to get the latest value for the given table (metric)
    '''
    CREATE OR REPLACE VIEW api.latest_{{ .table.Name }} AS
    SELECT
      d.time         AS "timestamp",
      d.value::TEXT  AS "value"
    FROM {{ .table.WithSchema "common" }} as d
    ORDER BY d.time DESC
    LIMIT 1;
    GRANT SELECT ON api.latest_{{ .table.Name }} TO web_anon;
    '''
  ]

[[outputs.prometheus_client]]
  listen = ":9274"
  path = "/metrics"
  expiration_interval = "60s"
  collectors_exclude = ["gocollector", "process"]
